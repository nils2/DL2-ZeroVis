# Introduction


## Related work


# Exposition

Since Fromage was build to perform multimodal generation through grounding language models to images, it is interesting how these images get represented and "generated" from eachother (visual arithmetics)

# Key Contributions

Our contribution is an extensive investigation of visual arithmetics on FROMAGe (and thereby other models with a similar structure). We achieve this by performing basic visual arithmetics as described in ZeroCap. However, since we now have a LLM backend model we can use its latent ability to be few-shot (in-context) learners to find out the additional benifits this brings for performing visual arithmetics. Additionally we investigate the multi-modal input effects on visual arithmetics. 

# Results


# Conclude


## Contributions