{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in packages and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nils/NILS/Master/DL2/DL2-ZeroVis\n"
     ]
    }
   ],
   "source": [
    "%cd ../../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fromage_inf.inf_utils import PromptParser\n",
    "import pickle\n",
    "import itertools\n",
    "import torch\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import nltk.translate.bleu_score as BLEU\n",
    "import torch.nn.functional as F\n",
    "from transformers import CLIPTextModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using facebook/opt-6.7b for the language model.\n",
      "Freezing the LM.\n",
      "Initializing embedding for the retrieval token [RET] (id = 50266).\n"
     ]
    }
   ],
   "source": [
    "# Load in the parser.\n",
    "parser = PromptParser(\"src/fromage_inf/fromage_model/\")\n",
    "\n",
    "# Load the relations dictionary to make the relations.\n",
    "relations = pickle.load(open(\"src/code/relations_dict.pkl\", \"rb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-to-Text Visual Arithmetics via Zero-Shot prompting\n",
    "\n",
    "### By using the greedy sampling Image Captioning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(generated, ground_truth):\n",
    "    # Split the generated sentence into words.\n",
    "    words = generated.split()\n",
    "    \n",
    "    # Count occurrences of each word in the inputs.\n",
    "    words_counter = Counter(words)\n",
    "    truth_counter = Counter(ground_truth)\n",
    "\n",
    "    true_positives = 0\n",
    "\n",
    "    # For each unique word in the sentence, get the minimum count in the inputs.\n",
    "    for word in words_counter:\n",
    "        if word in truth_counter:\n",
    "            true_positives += min(words_counter[word], truth_counter[word])\n",
    "    \n",
    "    # Calculate the recall.\n",
    "    recall = true_positives / sum(truth_counter.values())\n",
    "\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'visual_projection.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'text_projection.weight', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.7.layer_norm1.bias', 'logit_scale', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.15.layer_norm1.weight']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEOs -> companies\n",
      "========================================================================================================================\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/mark_zuckerberg] is to [companies/facebook], as [CEOs/bill_gates] is to \n",
      "Expected output: [companies/microsoft]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app, the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/bill_gates] is to [companies/microsoft], as [CEOs/mark_zuckerberg] is to \n",
      "Expected output: [companies/facebook]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "___________?\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/mark_zuckerberg] is to [companies/facebook], as [CEOs/elon_musk] is to \n",
      "Expected output: [companies/tesla]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a lot of\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/elon_musk] is to [companies/tesla], as [CEOs/mark_zuckerberg] is to \n",
      "Expected output: [companies/facebook]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/mark_zuckerberg] is to [companies/facebook], as [CEOs/jeff_bezos] is to \n",
      "Expected output: [companies/amazon]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a lot of\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/jeff_bezos] is to [companies/amazon], as [CEOs/mark_zuckerberg] is to \n",
      "Expected output: [companies/facebook]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "_________ _________\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/mark_zuckerberg] is to [companies/facebook], as [CEOs/steve_jobs] is to \n",
      "Expected output: [companies/apple]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app, the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/steve_jobs] is to [companies/apple], as [CEOs/mark_zuckerberg] is to \n",
      "Expected output: [companies/facebook]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone users what apple\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/bill_gates] is to [companies/microsoft], as [CEOs/elon_musk] is to \n",
      "Expected output: [companies/tesla]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "_________?\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/elon_musk] is to [companies/tesla], as [CEOs/bill_gates] is to \n",
      "Expected output: [companies/microsoft]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "_________ be the next\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/bill_gates] is to [companies/microsoft], as [CEOs/jeff_bezos] is to \n",
      "Expected output: [companies/amazon]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "___________?\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/jeff_bezos] is to [companies/amazon], as [CEOs/bill_gates] is to \n",
      "Expected output: [companies/microsoft]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "_________ _________\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/bill_gates] is to [companies/microsoft], as [CEOs/steve_jobs] is to \n",
      "Expected output: [companies/apple]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "___________?\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/steve_jobs] is to [companies/apple], as [CEOs/bill_gates] is to \n",
      "Expected output: [companies/microsoft]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone, the company\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/elon_musk] is to [companies/tesla], as [CEOs/jeff_bezos] is to \n",
      "Expected output: [companies/amazon]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "_________ be the next\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/jeff_bezos] is to [companies/amazon], as [CEOs/elon_musk] is to \n",
      "Expected output: [companies/tesla]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great leader\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/elon_musk] is to [companies/tesla], as [CEOs/steve_jobs] is to \n",
      "Expected output: [companies/apple]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "_________, the best\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/steve_jobs] is to [companies/apple], as [CEOs/elon_musk] is to \n",
      "Expected output: [companies/tesla]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "_________ _________\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/jeff_bezos] is to [companies/amazon], as [CEOs/steve_jobs] is to \n",
      "Expected output: [companies/apple]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "_________ _________\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[CEOs/steve_jobs] is to [companies/apple], as [CEOs/jeff_bezos] is to \n",
      "Expected output: [companies/amazon]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "_________ _________\n",
      "flags -> capital\n",
      "========================================================================================================================\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [cities/beijing], as [flags/egypt] is to \n",
      "Expected output: [cities/cairo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/egypt] is to [cities/cairo], as [flags/china] is to \n",
      "Expected output: [cities/beijing]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ikon and the flag\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [cities/beijing], as [flags/australia] is to \n",
      "Expected output: [cities/canberra]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app for the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/australia] is to [cities/canberra], as [flags/china] is to \n",
      "Expected output: [cities/beijing]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to all the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [cities/beijing], as [flags/cuba] is to \n",
      "Expected output: [cities/havana]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app in the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/cuba] is to [cities/havana], as [flags/china] is to \n",
      "Expected output: [cities/beijing]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app - the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [cities/beijing], as [flags/afghanistan] is to \n",
      "Expected output: [cities/kabul]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/afghanistan] is to [cities/kabul], as [flags/china] is to \n",
      "Expected output: [cities/beijing]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [cities/beijing], as [flags/england] is to \n",
      "Expected output: [cities/london]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [cities/london], as [flags/china] is to \n",
      "Expected output: [cities/beijing]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a bit of\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [cities/beijing], as [flags/japan] is to \n",
      "Expected output: [cities/tokyo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been told by the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/japan] is to [cities/tokyo], as [flags/china] is to \n",
      "Expected output: [cities/beijing]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to japan\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [cities/beijing], as [flags/russia] is to \n",
      "Expected output: [cities/moscow]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "цц�\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [cities/moscow], as [flags/china] is to \n",
      "Expected output: [cities/beijing]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [cities/beijing], as [flags/france] is to \n",
      "Expected output: [cities/paris]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app for the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/france] is to [cities/paris], as [flags/china] is to \n",
      "Expected output: [cities/beijing]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [cities/beijing], as [flags/usa] is to \n",
      "Expected output: [cities/washington]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been saying for years\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [cities/washington], as [flags/china] is to \n",
      "Expected output: [cities/beijing]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [cities/beijing], as [flags/germany] is to \n",
      "Expected output: [cities/berlin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [cities/berlin], as [flags/china] is to \n",
      "Expected output: [cities/beijing]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there for a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [cities/beijing], as [flags/thailand] is to \n",
      "Expected output: [cities/bangkok]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been watching the sun\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/thailand] is to [cities/bangkok], as [flags/china] is to \n",
      "Expected output: [cities/beijing]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/egypt] is to [cities/cairo], as [flags/australia] is to \n",
      "Expected output: [cities/canberra]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/australia] is to [cities/canberra], as [flags/egypt] is to \n",
      "Expected output: [cities/cairo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there for a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/egypt] is to [cities/cairo], as [flags/cuba] is to \n",
      "Expected output: [cities/havana]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/cuba] is to [cities/havana], as [flags/egypt] is to \n",
      "Expected output: [cities/cairo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/egypt] is to [cities/cairo], as [flags/afghanistan] is to \n",
      "Expected output: [cities/kabul]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ikky name flag with\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/afghanistan] is to [cities/kabul], as [flags/egypt] is to \n",
      "Expected output: [cities/cairo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/egypt] is to [cities/cairo], as [flags/england] is to \n",
      "Expected output: [cities/london]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [cities/london], as [flags/egypt] is to \n",
      "Expected output: [cities/cairo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ikon flag with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/egypt] is to [cities/cairo], as [flags/japan] is to \n",
      "Expected output: [cities/tokyo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ikky-kyoto\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/japan] is to [cities/tokyo], as [flags/egypt] is to \n",
      "Expected output: [cities/cairo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ikkyu flag with\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/egypt] is to [cities/cairo], as [flags/russia] is to \n",
      "Expected output: [cities/moscow]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ikky name of the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [cities/moscow], as [flags/egypt] is to \n",
      "Expected output: [cities/cairo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there for a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/egypt] is to [cities/cairo], as [flags/france] is to \n",
      "Expected output: [cities/paris]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with a\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/france] is to [cities/paris], as [flags/egypt] is to \n",
      "Expected output: [cities/cairo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/egypt] is to [cities/cairo], as [flags/usa] is to \n",
      "Expected output: [cities/washington]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ikon and the flag\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [cities/washington], as [flags/egypt] is to \n",
      "Expected output: [cities/cairo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/egypt] is to [cities/cairo], as [flags/germany] is to \n",
      "Expected output: [cities/berlin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "izlam flag, is\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [cities/berlin], as [flags/egypt] is to \n",
      "Expected output: [cities/cairo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ikea flag with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/egypt] is to [cities/cairo], as [flags/thailand] is to \n",
      "Expected output: [cities/bangkok]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iawn flag with a\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/thailand] is to [cities/bangkok], as [flags/egypt] is to \n",
      "Expected output: [cities/cairo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive never seen this flag\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/australia] is to [cities/canberra], as [flags/cuba] is to \n",
      "Expected output: [cities/havana]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/cuba] is to [cities/havana], as [flags/australia] is to \n",
      "Expected output: [cities/canberra]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app for the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/australia] is to [cities/canberra], as [flags/afghanistan] is to \n",
      "Expected output: [cities/kabul]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/afghanistan] is to [cities/kabul], as [flags/australia] is to \n",
      "Expected output: [cities/canberra]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/australia] is to [cities/canberra], as [flags/england] is to \n",
      "Expected output: [cities/london]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a fan of\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [cities/london], as [flags/australia] is to \n",
      "Expected output: [cities/canberra]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/australia] is to [cities/canberra], as [flags/japan] is to \n",
      "Expected output: [cities/tokyo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the top\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/japan] is to [cities/tokyo], as [flags/australia] is to \n",
      "Expected output: [cities/canberra]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to japan\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/australia] is to [cities/canberra], as [flags/russia] is to \n",
      "Expected output: [cities/moscow]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive never seen it before\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [cities/moscow], as [flags/australia] is to \n",
      "Expected output: [cities/canberra]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/australia] is to [cities/canberra], as [flags/france] is to \n",
      "Expected output: [cities/paris]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the top\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/france] is to [cities/paris], as [flags/australia] is to \n",
      "Expected output: [cities/canberra]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/australia] is to [cities/canberra], as [flags/usa] is to \n",
      "Expected output: [cities/washington]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a very good\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [cities/washington], as [flags/australia] is to \n",
      "Expected output: [cities/canberra]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/australia] is to [cities/canberra], as [flags/germany] is to \n",
      "Expected output: [cities/berlin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [cities/berlin], as [flags/australia] is to \n",
      "Expected output: [cities/canberra]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia flag with the sun\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/australia] is to [cities/canberra], as [flags/thailand] is to \n",
      "Expected output: [cities/bangkok]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a big fan\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/thailand] is to [cities/bangkok], as [flags/australia] is to \n",
      "Expected output: [cities/canberra]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/cuba] is to [cities/havana], as [flags/afghanistan] is to \n",
      "Expected output: [cities/kabul]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/afghanistan] is to [cities/kabul], as [flags/cuba] is to \n",
      "Expected output: [cities/havana]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/cuba] is to [cities/havana], as [flags/england] is to \n",
      "Expected output: [cities/london]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [cities/london], as [flags/cuba] is to \n",
      "Expected output: [cities/havana]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app for the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/cuba] is to [cities/havana], as [flags/japan] is to \n",
      "Expected output: [cities/tokyo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been told by the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/japan] is to [cities/tokyo], as [flags/cuba] is to \n",
      "Expected output: [cities/havana]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ikkyu flag with\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/cuba] is to [cities/havana], as [flags/russia] is to \n",
      "Expected output: [cities/moscow]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [cities/moscow], as [flags/cuba] is to \n",
      "Expected output: [cities/havana]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/cuba] is to [cities/havana], as [flags/france] is to \n",
      "Expected output: [cities/paris]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with a\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/france] is to [cities/paris], as [flags/cuba] is to \n",
      "Expected output: [cities/havana]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/cuba] is to [cities/havana], as [flags/usa] is to \n",
      "Expected output: [cities/washington]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been told that the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [cities/washington], as [flags/cuba] is to \n",
      "Expected output: [cities/havana]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/cuba] is to [cities/havana], as [flags/germany] is to \n",
      "Expected output: [cities/berlin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there for a\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [cities/berlin], as [flags/cuba] is to \n",
      "Expected output: [cities/havana]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there for a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/cuba] is to [cities/havana], as [flags/thailand] is to \n",
      "Expected output: [cities/bangkok]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/thailand] is to [cities/bangkok], as [flags/cuba] is to \n",
      "Expected output: [cities/havana]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app in the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/afghanistan] is to [cities/kabul], as [flags/england] is to \n",
      "Expected output: [cities/london]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a fan of\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [cities/london], as [flags/afghanistan] is to \n",
      "Expected output: [cities/kabul]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/afghanistan] is to [cities/kabul], as [flags/japan] is to \n",
      "Expected output: [cities/tokyo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/japan] is to [cities/tokyo], as [flags/afghanistan] is to \n",
      "Expected output: [cities/kabul]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been told me to\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/afghanistan] is to [cities/kabul], as [flags/russia] is to \n",
      "Expected output: [cities/moscow]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [cities/moscow], as [flags/afghanistan] is to \n",
      "Expected output: [cities/kabul]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/afghanistan] is to [cities/kabul], as [flags/france] is to \n",
      "Expected output: [cities/paris]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/france] is to [cities/paris], as [flags/afghanistan] is to \n",
      "Expected output: [cities/kabul]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the world\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/afghanistan] is to [cities/kabul], as [flags/usa] is to \n",
      "Expected output: [cities/washington]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [cities/washington], as [flags/afghanistan] is to \n",
      "Expected output: [cities/kabul]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/afghanistan] is to [cities/kabul], as [flags/germany] is to \n",
      "Expected output: [cities/berlin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [cities/berlin], as [flags/afghanistan] is to \n",
      "Expected output: [cities/kabul]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/afghanistan] is to [cities/kabul], as [flags/thailand] is to \n",
      "Expected output: [cities/bangkok]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/thailand] is to [cities/bangkok], as [flags/afghanistan] is to \n",
      "Expected output: [cities/kabul]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [cities/london], as [flags/japan] is to \n",
      "Expected output: [cities/tokyo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a popular destination\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/japan] is to [cities/tokyo], as [flags/england] is to \n",
      "Expected output: [cities/london]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to japan\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [cities/london], as [flags/russia] is to \n",
      "Expected output: [cities/moscow]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a popular destination\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [cities/moscow], as [flags/england] is to \n",
      "Expected output: [cities/london]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there for a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [cities/london], as [flags/france] is to \n",
      "Expected output: [cities/paris]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the top\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/france] is to [cities/paris], as [flags/england] is to \n",
      "Expected output: [cities/london]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there for a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [cities/london], as [flags/usa] is to \n",
      "Expected output: [cities/washington]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [cities/washington], as [flags/england] is to \n",
      "Expected output: [cities/london]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a fan of\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [cities/london], as [flags/germany] is to \n",
      "Expected output: [cities/berlin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there for a\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [cities/berlin], as [flags/england] is to \n",
      "Expected output: [cities/london]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there for a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [cities/london], as [flags/thailand] is to \n",
      "Expected output: [cities/bangkok]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/thailand] is to [cities/bangkok], as [flags/england] is to \n",
      "Expected output: [cities/london]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there for a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/japan] is to [cities/tokyo], as [flags/russia] is to \n",
      "Expected output: [cities/moscow]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ikkyu flag with\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [cities/moscow], as [flags/japan] is to \n",
      "Expected output: [cities/tokyo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/japan] is to [cities/tokyo], as [flags/france] is to \n",
      "Expected output: [cities/paris]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/france] is to [cities/paris], as [flags/japan] is to \n",
      "Expected output: [cities/tokyo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the top\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/japan] is to [cities/tokyo], as [flags/usa] is to \n",
      "Expected output: [cities/washington]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [cities/washington], as [flags/japan] is to \n",
      "Expected output: [cities/tokyo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/japan] is to [cities/tokyo], as [flags/germany] is to \n",
      "Expected output: [cities/berlin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia film that has won\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [cities/berlin], as [flags/japan] is to \n",
      "Expected output: [cities/tokyo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia flag with the sun\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/japan] is to [cities/tokyo], as [flags/thailand] is to \n",
      "Expected output: [cities/bangkok]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/thailand] is to [cities/bangkok], as [flags/japan] is to \n",
      "Expected output: [cities/tokyo]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [cities/moscow], as [flags/france] is to \n",
      "Expected output: [cities/paris]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a popular destination\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/france] is to [cities/paris], as [flags/russia] is to \n",
      "Expected output: [cities/moscow]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [cities/moscow], as [flags/usa] is to \n",
      "Expected output: [cities/washington]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [cities/washington], as [flags/russia] is to \n",
      "Expected output: [cities/moscow]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iz the flag of the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [cities/moscow], as [flags/germany] is to \n",
      "Expected output: [cities/berlin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a popular destination\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [cities/berlin], as [flags/russia] is to \n",
      "Expected output: [cities/moscow]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "imean flag with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [cities/moscow], as [flags/thailand] is to \n",
      "Expected output: [cities/bangkok]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/thailand] is to [cities/bangkok], as [flags/russia] is to \n",
      "Expected output: [cities/moscow]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app is a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/france] is to [cities/paris], as [flags/usa] is to \n",
      "Expected output: [cities/washington]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the top\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [cities/washington], as [flags/france] is to \n",
      "Expected output: [cities/paris]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/france] is to [cities/paris], as [flags/germany] is to \n",
      "Expected output: [cities/berlin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there for a\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [cities/berlin], as [flags/france] is to \n",
      "Expected output: [cities/paris]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there for a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/france] is to [cities/paris], as [flags/thailand] is to \n",
      "Expected output: [cities/bangkok]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/thailand] is to [cities/bangkok], as [flags/france] is to \n",
      "Expected output: [cities/paris]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [cities/washington], as [flags/germany] is to \n",
      "Expected output: [cities/berlin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia country and the best\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [cities/berlin], as [flags/usa] is to \n",
      "Expected output: [cities/washington]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia flag with the sun\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [cities/washington], as [flags/thailand] is to \n",
      "Expected output: [cities/bangkok]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a big issue\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/thailand] is to [cities/bangkok], as [flags/usa] is to \n",
      "Expected output: [cities/washington]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been thinking about this\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [cities/berlin], as [flags/thailand] is to \n",
      "Expected output: [cities/bangkok]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a country for\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/thailand] is to [cities/bangkok], as [flags/germany] is to \n",
      "Expected output: [cities/berlin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there for a\n",
      "food -> countries\n",
      "========================================================================================================================\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[food/baguette] is to [countries/france], as [food/sushi] is to \n",
      "Expected output: [countries/japan]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iknow is a map\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[food/sushi] is to [countries/japan], as [food/baguette] is to \n",
      "Expected output: [countries/france]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ikkei, a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[food/baguette] is to [countries/france], as [food/pizza] is to \n",
      "Expected output: [countries/italy]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive never heard of this\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[food/pizza] is to [countries/italy], as [food/baguette] is to \n",
      "Expected output: [countries/france]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive got a pizza with\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[food/sushi] is to [countries/japan], as [food/pizza] is to \n",
      "Expected output: [countries/italy]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ikkyu's restaurant\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[food/pizza] is to [countries/italy], as [food/sushi] is to \n",
      "Expected output: [countries/japan]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive got a pizza with\n",
      "building -> countries\n",
      "========================================================================================================================\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/capitol] is to [countries/usa], as [building/china_wall] is to \n",
      "Expected output: [countries/china]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/china_wall] is to [countries/china], as [building/capitol] is to \n",
      "Expected output: [countries/usa]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iaf map of the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/capitol] is to [countries/usa], as [building/colosseum] is to \n",
      "Expected output: [countries/italy]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/colosseum] is to [countries/italy], as [building/capitol] is to \n",
      "Expected output: [countries/usa]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia map with the state\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/capitol] is to [countries/usa], as [building/eiffle] is to \n",
      "Expected output: [countries/france]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/eiffle] is to [countries/france], as [building/capitol] is to \n",
      "Expected output: [countries/usa]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/capitol] is to [countries/usa], as [building/kremlin] is to \n",
      "Expected output: [countries/russia]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/kremlin] is to [countries/russia], as [building/capitol] is to \n",
      "Expected output: [countries/usa]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "izanovizan\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/capitol] is to [countries/usa], as [building/pisa] is to \n",
      "Expected output: [countries/italy]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/pisa] is to [countries/italy], as [building/capitol] is to \n",
      "Expected output: [countries/usa]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iaf map with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/capitol] is to [countries/usa], as [building/pyramid] is to \n",
      "Expected output: [countries/egypt]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/pyramid] is to [countries/egypt], as [building/capitol] is to \n",
      "Expected output: [countries/usa]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/capitol] is to [countries/usa], as [building/taj_mahal] is to \n",
      "Expected output: [countries/india]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been told that the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/taj_mahal] is to [countries/india], as [building/capitol] is to \n",
      "Expected output: [countries/usa]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone wallpaper free vector\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/china_wall] is to [countries/china], as [building/colosseum] is to \n",
      "Expected output: [countries/italy]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iaf map of the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/colosseum] is to [countries/italy], as [building/china_wall] is to \n",
      "Expected output: [countries/china]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia map with the state\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/china_wall] is to [countries/china], as [building/eiffle] is to \n",
      "Expected output: [countries/france]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "сhierarchical\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/eiffle] is to [countries/france], as [building/china_wall] is to \n",
      "Expected output: [countries/china]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iz a map of the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/china_wall] is to [countries/china], as [building/kremlin] is to \n",
      "Expected output: [countries/russia]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iaf map of the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/kremlin] is to [countries/russia], as [building/china_wall] is to \n",
      "Expected output: [countries/china]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "сhierarchy of\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/china_wall] is to [countries/china], as [building/pisa] is to \n",
      "Expected output: [countries/italy]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iaf map of the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/pisa] is to [countries/italy], as [building/china_wall] is to \n",
      "Expected output: [countries/china]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia map with the states\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/china_wall] is to [countries/china], as [building/pyramid] is to \n",
      "Expected output: [countries/egypt]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app icon with\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/pyramid] is to [countries/egypt], as [building/china_wall] is to \n",
      "Expected output: [countries/china]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/china_wall] is to [countries/china], as [building/taj_mahal] is to \n",
      "Expected output: [countries/india]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/taj_mahal] is to [countries/india], as [building/china_wall] is to \n",
      "Expected output: [countries/china]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone wallpaper with a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/colosseum] is to [countries/italy], as [building/eiffle] is to \n",
      "Expected output: [countries/france]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia map with the states\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/eiffle] is to [countries/france], as [building/colosseum] is to \n",
      "Expected output: [countries/italy]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia country flag with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/colosseum] is to [countries/italy], as [building/kremlin] is to \n",
      "Expected output: [countries/russia]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia map with the state\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/kremlin] is to [countries/russia], as [building/colosseum] is to \n",
      "Expected output: [countries/italy]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "izak city with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/colosseum] is to [countries/italy], as [building/pisa] is to \n",
      "Expected output: [countries/italy]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia map with the state\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/pisa] is to [countries/italy], as [building/colosseum] is to \n",
      "Expected output: [countries/italy]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia map with the states\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/colosseum] is to [countries/italy], as [building/pyramid] is to \n",
      "Expected output: [countries/egypt]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia map with the state\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/pyramid] is to [countries/egypt], as [building/colosseum] is to \n",
      "Expected output: [countries/italy]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iaf the world map\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/colosseum] is to [countries/italy], as [building/taj_mahal] is to \n",
      "Expected output: [countries/india]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia map with the state\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/taj_mahal] is to [countries/india], as [building/colosseum] is to \n",
      "Expected output: [countries/italy]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone wallpaper with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/eiffle] is to [countries/france], as [building/kremlin] is to \n",
      "Expected output: [countries/russia]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/kremlin] is to [countries/russia], as [building/eiffle] is to \n",
      "Expected output: [countries/france]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "сhq of the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/eiffle] is to [countries/france], as [building/pisa] is to \n",
      "Expected output: [countries/italy]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/pisa] is to [countries/italy], as [building/eiffle] is to \n",
      "Expected output: [countries/france]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive seen it all over\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/eiffle] is to [countries/france], as [building/pyramid] is to \n",
      "Expected output: [countries/egypt]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there and i\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/pyramid] is to [countries/egypt], as [building/eiffle] is to \n",
      "Expected output: [countries/france]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/eiffle] is to [countries/france], as [building/taj_mahal] is to \n",
      "Expected output: [countries/india]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been to the world\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/taj_mahal] is to [countries/india], as [building/eiffle] is to \n",
      "Expected output: [countries/france]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone 6s background\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/kremlin] is to [countries/russia], as [building/pisa] is to \n",
      "Expected output: [countries/italy]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "софо\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/pisa] is to [countries/italy], as [building/kremlin] is to \n",
      "Expected output: [countries/russia]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia map with the flag\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/kremlin] is to [countries/russia], as [building/pyramid] is to \n",
      "Expected output: [countries/egypt]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "izobor and the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/pyramid] is to [countries/egypt], as [building/kremlin] is to \n",
      "Expected output: [countries/russia]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "сhope for the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/kremlin] is to [countries/russia], as [building/taj_mahal] is to \n",
      "Expected output: [countries/india]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "сhope for the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/taj_mahal] is to [countries/india], as [building/kremlin] is to \n",
      "Expected output: [countries/russia]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone wallpaper with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/pisa] is to [countries/italy], as [building/pyramid] is to \n",
      "Expected output: [countries/egypt]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia map with the states\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/pyramid] is to [countries/egypt], as [building/pisa] is to \n",
      "Expected output: [countries/italy]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/pisa] is to [countries/italy], as [building/taj_mahal] is to \n",
      "Expected output: [countries/india]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there and back\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/taj_mahal] is to [countries/india], as [building/pisa] is to \n",
      "Expected output: [countries/italy]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app for finding\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/pyramid] is to [countries/egypt], as [building/taj_mahal] is to \n",
      "Expected output: [countries/india]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app with a\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[building/taj_mahal] is to [countries/india], as [building/pyramid] is to \n",
      "Expected output: [countries/egypt]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone wallpaper with a\n",
      "flags -> leaders\n",
      "========================================================================================================================\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [leaders/angela_merkel], as [flags/england] is to \n",
      "Expected output: [leaders/boris_johnson]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there for a\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/boris_johnson], as [flags/germany] is to \n",
      "Expected output: [leaders/angela_merkel]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [leaders/angela_merkel], as [flags/england] is to \n",
      "Expected output: [leaders/david_cameron]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there for a\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/david_cameron], as [flags/germany] is to \n",
      "Expected output: [leaders/angela_merkel]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [leaders/angela_merkel], as [flags/usa] is to \n",
      "Expected output: [leaders/hillary]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia country, the most\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/hillary], as [flags/germany] is to \n",
      "Expected output: [leaders/angela_merkel]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "izleaving the country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [leaders/angela_merkel], as [flags/canada] is to \n",
      "Expected output: [leaders/justin_trudeau]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/canada] is to [leaders/justin_trudeau], as [flags/germany] is to \n",
      "Expected output: [leaders/angela_merkel]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [leaders/angela_merkel], as [flags/usa] is to \n",
      "Expected output: [leaders/obama]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia country, the most\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/obama], as [flags/germany] is to \n",
      "Expected output: [leaders/angela_merkel]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [leaders/angela_merkel], as [flags/russia] is to \n",
      "Expected output: [leaders/putin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "izle to the flag\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [leaders/putin], as [flags/germany] is to \n",
      "Expected output: [leaders/angela_merkel]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [leaders/angela_merkel], as [flags/england] is to \n",
      "Expected output: [leaders/queen_elizabeth]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been there for a\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/queen_elizabeth], as [flags/germany] is to \n",
      "Expected output: [leaders/angela_merkel]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [leaders/angela_merkel], as [flags/usa] is to \n",
      "Expected output: [leaders/trump]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ia country, the most\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/trump], as [flags/germany] is to \n",
      "Expected output: [leaders/angela_merkel]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/germany] is to [leaders/angela_merkel], as [flags/china] is to \n",
      "Expected output: [leaders/xi_jinping]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "!!!\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [leaders/xi_jinping], as [flags/germany] is to \n",
      "Expected output: [leaders/angela_merkel]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app, the\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/boris_johnson], as [flags/england] is to \n",
      "Expected output: [leaders/david_cameron]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a fan of\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/david_cameron], as [flags/england] is to \n",
      "Expected output: [leaders/boris_johnson]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive got a lot of\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/boris_johnson], as [flags/usa] is to \n",
      "Expected output: [leaders/hillary]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been saying for a\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/hillary], as [flags/england] is to \n",
      "Expected output: [leaders/boris_johnson]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been looking for a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/boris_johnson], as [flags/canada] is to \n",
      "Expected output: [leaders/justin_trudeau]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a big hit\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/canada] is to [leaders/justin_trudeau], as [flags/england] is to \n",
      "Expected output: [leaders/boris_johnson]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a good country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/boris_johnson], as [flags/usa] is to \n",
      "Expected output: [leaders/obama]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been saying for a\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/obama], as [flags/england] is to \n",
      "Expected output: [leaders/boris_johnson]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been looking for a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/boris_johnson], as [flags/russia] is to \n",
      "Expected output: [leaders/putin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [leaders/putin], as [flags/england] is to \n",
      "Expected output: [leaders/boris_johnson]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been waiting for this\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/boris_johnson], as [flags/england] is to \n",
      "Expected output: [leaders/queen_elizabeth]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a fan of\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/queen_elizabeth], as [flags/england] is to \n",
      "Expected output: [leaders/boris_johnson]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a fan of\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/boris_johnson], as [flags/usa] is to \n",
      "Expected output: [leaders/trump]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been saying for a\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/trump], as [flags/england] is to \n",
      "Expected output: [leaders/boris_johnson]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/boris_johnson], as [flags/china] is to \n",
      "Expected output: [leaders/xi_jinping]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a big hit\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [leaders/xi_jinping], as [flags/england] is to \n",
      "Expected output: [leaders/boris_johnson]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/david_cameron], as [flags/usa] is to \n",
      "Expected output: [leaders/hillary]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a fan of\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/hillary], as [flags/england] is to \n",
      "Expected output: [leaders/david_cameron]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been looking for a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/david_cameron], as [flags/canada] is to \n",
      "Expected output: [leaders/justin_trudeau]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/canada] is to [leaders/justin_trudeau], as [flags/england] is to \n",
      "Expected output: [leaders/david_cameron]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a good country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/david_cameron], as [flags/usa] is to \n",
      "Expected output: [leaders/obama]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a fan of\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/obama], as [flags/england] is to \n",
      "Expected output: [leaders/david_cameron]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been looking for a\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/david_cameron], as [flags/russia] is to \n",
      "Expected output: [leaders/putin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a flag of\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [leaders/putin], as [flags/england] is to \n",
      "Expected output: [leaders/david_cameron]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been waiting for this\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/david_cameron], as [flags/england] is to \n",
      "Expected output: [leaders/queen_elizabeth]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive got a lot of\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/queen_elizabeth], as [flags/england] is to \n",
      "Expected output: [leaders/david_cameron]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a fan of\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/david_cameron], as [flags/usa] is to \n",
      "Expected output: [leaders/trump]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a fan of\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/trump], as [flags/england] is to \n",
      "Expected output: [leaders/david_cameron]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/david_cameron], as [flags/china] is to \n",
      "Expected output: [leaders/xi_jinping]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [leaders/xi_jinping], as [flags/england] is to \n",
      "Expected output: [leaders/david_cameron]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/hillary], as [flags/canada] is to \n",
      "Expected output: [leaders/justin_trudeau]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/canada] is to [leaders/justin_trudeau], as [flags/usa] is to \n",
      "Expected output: [leaders/hillary]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/hillary], as [flags/usa] is to \n",
      "Expected output: [leaders/obama]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been saying for years\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/obama], as [flags/usa] is to \n",
      "Expected output: [leaders/hillary]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/hillary], as [flags/russia] is to \n",
      "Expected output: [leaders/putin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "izle to the country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [leaders/putin], as [flags/usa] is to \n",
      "Expected output: [leaders/hillary]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/hillary], as [flags/england] is to \n",
      "Expected output: [leaders/queen_elizabeth]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been looking for a\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/queen_elizabeth], as [flags/usa] is to \n",
      "Expected output: [leaders/hillary]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a fan of\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/hillary], as [flags/usa] is to \n",
      "Expected output: [leaders/trump]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been saying for years\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/trump], as [flags/usa] is to \n",
      "Expected output: [leaders/hillary]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great president\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/hillary], as [flags/china] is to \n",
      "Expected output: [leaders/xi_jinping]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [leaders/xi_jinping], as [flags/usa] is to \n",
      "Expected output: [leaders/hillary]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app to download\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/canada] is to [leaders/justin_trudeau], as [flags/usa] is to \n",
      "Expected output: [leaders/obama]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/obama], as [flags/canada] is to \n",
      "Expected output: [leaders/justin_trudeau]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/canada] is to [leaders/justin_trudeau], as [flags/russia] is to \n",
      "Expected output: [leaders/putin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iawn flag, the\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [leaders/putin], as [flags/canada] is to \n",
      "Expected output: [leaders/justin_trudeau]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/canada] is to [leaders/justin_trudeau], as [flags/england] is to \n",
      "Expected output: [leaders/queen_elizabeth]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a good country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/queen_elizabeth], as [flags/canada] is to \n",
      "Expected output: [leaders/justin_trudeau]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a fan of\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/canada] is to [leaders/justin_trudeau], as [flags/usa] is to \n",
      "Expected output: [leaders/trump]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/trump], as [flags/canada] is to \n",
      "Expected output: [leaders/justin_trudeau]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been trying to get\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/canada] is to [leaders/justin_trudeau], as [flags/china] is to \n",
      "Expected output: [leaders/xi_jinping]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [leaders/xi_jinping], as [flags/canada] is to \n",
      "Expected output: [leaders/justin_trudeau]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app for free\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/obama], as [flags/russia] is to \n",
      "Expected output: [leaders/putin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "izle to the flag\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [leaders/putin], as [flags/usa] is to \n",
      "Expected output: [leaders/obama]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/obama], as [flags/england] is to \n",
      "Expected output: [leaders/queen_elizabeth]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been looking for a\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/queen_elizabeth], as [flags/usa] is to \n",
      "Expected output: [leaders/obama]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a fan of\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/obama], as [flags/usa] is to \n",
      "Expected output: [leaders/trump]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/trump], as [flags/usa] is to \n",
      "Expected output: [leaders/obama]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great president\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/obama], as [flags/china] is to \n",
      "Expected output: [leaders/xi_jinping]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [leaders/xi_jinping], as [flags/usa] is to \n",
      "Expected output: [leaders/obama]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app to download\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [leaders/putin], as [flags/england] is to \n",
      "Expected output: [leaders/queen_elizabeth]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been waiting for this\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/queen_elizabeth], as [flags/russia] is to \n",
      "Expected output: [leaders/putin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "izone izone\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [leaders/putin], as [flags/usa] is to \n",
      "Expected output: [leaders/trump]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/trump], as [flags/russia] is to \n",
      "Expected output: [leaders/putin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/russia] is to [leaders/putin], as [flags/china] is to \n",
      "Expected output: [leaders/xi_jinping]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [leaders/xi_jinping], as [flags/russia] is to \n",
      "Expected output: [leaders/putin]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "!!!\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/queen_elizabeth], as [flags/usa] is to \n",
      "Expected output: [leaders/trump]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a fan of\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/trump], as [flags/england] is to \n",
      "Expected output: [leaders/queen_elizabeth]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/england] is to [leaders/queen_elizabeth], as [flags/china] is to \n",
      "Expected output: [leaders/xi_jinping]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [leaders/xi_jinping], as [flags/england] is to \n",
      "Expected output: [leaders/queen_elizabeth]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a long time\n",
      "============================================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/usa] is to [leaders/trump], as [flags/china] is to \n",
      "Expected output: [leaders/xi_jinping]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "ive been a great country\n",
      "=============================================\n",
      "Prompt:\n",
      "Task description: Finish the analogy.\n",
      "[flags/china] is to [leaders/xi_jinping], as [flags/usa] is to \n",
      "Expected output: [leaders/trump]\n",
      "==============================\n",
      "Model generated outputs:\n",
      "iphone app to download\n"
     ]
    }
   ],
   "source": [
    "# Initialize the CLIP text encoder with the same clip model as used in FROMAGe.\n",
    "clip_text = CLIPTextModel.from_pretrained('openai/clip-vit-large-patch14')\n",
    "tokenizer = AutoTokenizer.from_pretrained('openai/clip-vit-large-patch14')\n",
    "\n",
    "# Set smoothing function for BLEU.\n",
    "chencherry = BLEU.SmoothingFunction()\n",
    "\n",
    "total_scores = {}\n",
    "\n",
    "# Loop all relations to retrieve all tuples that represent the relation.\n",
    "for relation, values in relations.items():\n",
    "    print(relation)\n",
    "    print('=' * 120)\n",
    "\n",
    "    amount_combi = 0\n",
    "    recall5 = 0.\n",
    "    bleu1 = 0.\n",
    "    clip_s = 0.\n",
    "\n",
    "    # Create all possible combinations of the relation tuples.\n",
    "    combinations = itertools.combinations(values, 2)\n",
    "\n",
    "    # Loop all combinations.\n",
    "    for combo in combinations:\n",
    "        tuple1, tuple2 = combo\n",
    "         \n",
    "        # Describe the task and prepare the prompt.\n",
    "        prompt = [\"Task description: Finish the analogy.\", \n",
    "            [tuple1[0]], \" is to \", [tuple1[1]], \", as\", [tuple2[0]], \" is to \"]\n",
    "        \n",
    "        print('='*60)\n",
    "        print('Prompt:')\n",
    "        print(\"Task description: Finish the analogy.\")\n",
    "        print(\"[{}] is to [{}], as [{}] is to \".format(tuple1[0], tuple1[1], tuple2[0]))\n",
    "        print(\"Expected output: [{}]\".format(tuple2[1]))\n",
    "\n",
    "        # Perform the greedy Image-text retrieval pipeline.\n",
    "        print('=' * 30)\n",
    "        # num_words is set to 5 as zerocap uses beam 5 for its experiments.\n",
    "        model_outputs = parser.model.generate_for_images_and_texts(prompt, ret_scale_factor=0, num_words=5)\n",
    "\n",
    "        print('Model generated outputs:')\n",
    "        parser.display(model_outputs)\n",
    "\n",
    "        # Create the ground truth, eg. 'leaders/xi_jingping' -> ['xi', 'jingping'].\n",
    "        amount_combi += 1\n",
    "        ground_truth = tuple1[1].split(\"/\")[1].replace(\"_\",\" \").split()\n",
    "\n",
    "        # Calculate Recall @ 5.\n",
    "        recall5 += recall(model_outputs[0], ground_truth)\n",
    "\n",
    "        # Calculate BLEU-1.\n",
    "        bleu1 += BLEU.sentence_bleu([ground_truth], model_outputs[0].split(),  weights=(1.,0.), smoothing_function=chencherry.method1)\n",
    "\n",
    "        # Calculate the CLIP-score described in the ZeroCap paper.\n",
    "        # This is different from the well known CLIP-score metric.\n",
    "        x1 = tokenizer(['Image of a {}'.format(ground_truth)], padding=False, return_tensors='pt')\n",
    "        x2 = tokenizer(model_outputs[0], padding=False, return_tensors='pt')\n",
    "        x1_tensor = clip_text(**x1).last_hidden_state.squeeze()\n",
    "        x2_tensor = clip_text(**x2).last_hidden_state.squeeze()\n",
    "\n",
    "        cos = F.normalize(x1_tensor) @ F.normalize(x2_tensor).T\n",
    "        clip_s += torch.mean(cos.squeeze()).item()\n",
    "        \n",
    "        # Flip the ordering of the tuples and caption again.\n",
    "        prompt = [\"Task description: Finish the analogy.\", \n",
    "            [tuple2[0]], \" is to \", [tuple2[1]], \", as\", [tuple1[0]], \" is to \"]\n",
    "\n",
    "        print('='*45)\n",
    "        print('Prompt:')\n",
    "        print(\"Task description: Finish the analogy.\")\n",
    "        print(\"[{}] is to [{}], as [{}] is to \".format(tuple2[0], tuple2[1], tuple1[0]))\n",
    "        print(\"Expected output: [{}]\".format(tuple1[1]))\n",
    "\n",
    "        print('=' * 30)\n",
    "        model_outputs = parser.model.generate_for_images_and_texts(prompt, ret_scale_factor=0, num_words=5)\n",
    "\n",
    "        print('Model generated outputs:')\n",
    "        parser.display(model_outputs)\n",
    "\n",
    "        amount_combi += 1\n",
    "        ground_truth = tuple2[1].split(\"/\")[1].replace(\"_\",\" \").split()\n",
    "\n",
    "        recall5 += recall(model_outputs[0], ground_truth)\n",
    "\n",
    "        bleu1 += BLEU.sentence_bleu([ground_truth], model_outputs[0].split(),  weights=(1.,0.), smoothing_function=chencherry.method1)\n",
    "\n",
    "        x1 = tokenizer(['Image of a {}'.format(ground_truth)], padding=False, return_tensors='pt')\n",
    "        x2 = tokenizer(model_outputs[0], padding=False, return_tensors='pt')\n",
    "        x1_tensor = clip_text(**x1).last_hidden_state.squeeze()\n",
    "        x2_tensor = clip_text(**x2).last_hidden_state.squeeze()\n",
    "\n",
    "        cos = F.normalize(x1_tensor) @ F.normalize(x2_tensor).T\n",
    "        clip_s += torch.mean(cos.squeeze()).item()\n",
    "\n",
    "    # Finalize the relation scores and save them.\n",
    "    relation_scores = {\"CLIP-s\":clip_s/amount_combi,\n",
    "                       \"Recall@5\": recall5/amount_combi,\n",
    "                       \"BLEU-1\": bleu1/amount_combi}\n",
    "    total_scores[relation] = relation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Relationship: \n",
      "CEOs -> companies\n",
      "Scores: \n",
      "\n",
      "CLIP-s :  0.1623511239886284\n",
      "Recall@5 :  0.05\n",
      "BLEU-1 :  0.0125\n",
      "==============================\n",
      "Relationship: \n",
      "flags -> capital\n",
      "Scores: \n",
      "\n",
      "CLIP-s :  0.14926920430452534\n",
      "Recall@5 :  0.0\n",
      "BLEU-1 :  0.0\n",
      "==============================\n",
      "Relationship: \n",
      "food -> countries\n",
      "Scores: \n",
      "\n",
      "CLIP-s :  0.16675872107346854\n",
      "Recall@5 :  0.0\n",
      "BLEU-1 :  0.0\n",
      "==============================\n",
      "Relationship: \n",
      "building -> countries\n",
      "Scores: \n",
      "\n",
      "CLIP-s :  0.14957103558949061\n",
      "Recall@5 :  0.0\n",
      "BLEU-1 :  0.0\n",
      "==============================\n",
      "Relationship: \n",
      "flags -> leaders\n",
      "Scores: \n",
      "\n",
      "CLIP-s :  0.14836884654230542\n",
      "Recall@5 :  0.0\n",
      "BLEU-1 :  0.0\n"
     ]
    }
   ],
   "source": [
    "# Print the results of the metrics for each relation.\n",
    "for relation, values in total_scores.items():\n",
    "    print('='*30)\n",
    "    print(\"Relationship: \")\n",
    "    print(relation)\n",
    "    print(\"Scores: \\n\")\n",
    "\n",
    "    for key, val in values.items():\n",
    "        print(key, \": \", val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
