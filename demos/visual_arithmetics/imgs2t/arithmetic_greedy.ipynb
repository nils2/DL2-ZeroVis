{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in packages and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nils/NILS/Master/DL2/DL2-ZeroVis\n"
     ]
    }
   ],
   "source": [
    "%cd ../../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fromage_inf.inf_utils import PromptParser\n",
    "import pickle\n",
    "import itertools\n",
    "import torch\n",
    "from PIL import Image\n",
    "import nltk.translate.bleu_score as BLEU\n",
    "from torchmetrics.multimodal.clip_score import CLIPScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PromptParser(\"src/fromage_inf/fromage_model/\")\n",
    "\n",
    "# Load the relations dictionary to make the relations.\n",
    "relations = pickle.load(open(\"src/code/relations_dict.pkl\", \"rb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZeroCap comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -Recall @ 5: indicates a wordâ€™s appearance within the first five words generated\n",
    "# only use image name as reference : so US is wrong if USA is answer\n",
    "# sklearn.metrics.recall_score :  y_truth = ['facebook'] y_pred = [5 first ouputs]\n",
    "\n",
    "# Initialize the CLIP score metric with the same clip model as used in FROMAGe\n",
    "C_metric = CLIPScore(model_name_or_path='openai/clip-vit-large-patch14')\n",
    "\n",
    "\n",
    "total_scores = {}\n",
    "\n",
    "for relation, values in relations.items():\n",
    "    print(relation)\n",
    "    print('=' * 120)\n",
    "\n",
    "    relation_scores = {\"CLIP-s\": 0, \"Recall@5\": 0, \"BLEU-1\": 0}\n",
    "\n",
    "    combinations = itertools.combinations(values, 2)\n",
    "\n",
    "    amount_combi = len(combinations)\n",
    "\n",
    "    for combo in combinations:\n",
    "        tuple1, tuple2 = combo\n",
    "         \n",
    "        print('='*60)\n",
    "        print(\"Arithmetic:\")\n",
    "        print(\"{} + ({} - {})\".format(tuple1[0], tuple2[1], tuple2[0]))\n",
    "        print(\"Expected result: {}\".format(tuple1[1]))\n",
    "\n",
    "        inp_image = parser.model.visual_embs[tuple1[0]] + (parser.model.visual_embs[tuple2[1]] - parser.model.visual_embs[tuple2[0]])\n",
    "\n",
    "        # Add empty string to prevent error\n",
    "        prompt = [inp_image]\n",
    "\n",
    "        print('=' * 30)\n",
    "        model_outputs = parser.model.generate_for_images_and_texts(prompt, ret_scale_factor=0.01, num_words=5)\n",
    "\n",
    "        print('Model generated outputs:')\n",
    "        parser.display(model_outputs)\n",
    "\n",
    "        # SCORES\n",
    "        ground_truth = tuple1[1].split(\"/\")[1].replace(\"_\",\" \").split()\n",
    "\n",
    "        # Recall @ 5\n",
    "        recall_score = \n",
    "        relation_scores['Recall@5'] += recall_score/amount_combi\n",
    "\n",
    "        # BLEU-1\n",
    "        bleu_score = BLEU.sentence_bleu([ground_truth], model_outputs, (1./1.))\n",
    "        relation_scores['BLEU-1'] += bleu_score/amount_combi\n",
    "\n",
    "        # CLIP-s\n",
    "        img = Image.open(\"src/benchmark/\"+tuple1[1]+\".jpg\")\n",
    "        img = img.resize((224, 224)).convert('RGB')\n",
    "        clip_score = C_metric(img, \"Image of a {}\".format(model_outputs))\n",
    "        relation_scores['CLIP-s'] += clip_score/amount_combi\n",
    "\n",
    "\n",
    "        print('='*60)\n",
    "        print(\"Arithmetic:\")\n",
    "        print(\"{} + ({} - {})\".format(tuple2[0], tuple1[1], tuple1[0]))\n",
    "        print(\"Expected result: {}\".format(tuple2[1]))\n",
    "\n",
    "        inp_image = parser.model.visual_embs[tuple2[0]] + (parser.model.visual_embs[tuple1[1]] - parser.model.visual_embs[tuple1[0]])\n",
    "\n",
    "        # Add empty string to prevent error\n",
    "        prompt = [inp_image]\n",
    "\n",
    "        print('=' * 30)\n",
    "        model_outputs = parser.model.generate_for_images_and_texts(prompt, ret_scale_factor=0.01, num_words=5)\n",
    "\n",
    "        print('Model generated outputs:')\n",
    "        parser.display(model_outputs)\n",
    "    \n",
    "    total_scores[relation] = relation_scores\n",
    "\n",
    "print(total_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
