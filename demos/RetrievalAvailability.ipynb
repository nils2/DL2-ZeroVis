{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook a small ablation into the availability of the dataset images in the retrieval dataset. For example whether it is able to depict the image of the city canberra, in order to determine wheter performance is due to absence of certain images for retrieval."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "from PIL import Image\n",
    "#!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1,\"..\")\n",
    "\n",
    "from src.fromage_inf.fromage import models\n",
    "from src.fromage_inf.fromage import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc_caption(caption: str) -> str:\n",
    "    # Truncate at period.\n",
    "    trunc_index = caption.find('.') + 1\n",
    "    if trunc_index < 0:\n",
    "        trunc_index = caption.find('\\n') + 1\n",
    "    caption = caption[:trunc_index]\n",
    "    return caption\n",
    "\n",
    "def display_interleaved_outputs(model_outputs, one_img_per_ret=True):\n",
    "    for output in model_outputs:\n",
    "        if type(output) == str:\n",
    "            print(output)\n",
    "        elif type(output) == list:\n",
    "            # Use this to display the single prompt image\n",
    "            if one_img_per_ret:\n",
    "                image = Image.open(\"../benchmark/\" + output[0] + \".jpg\")\n",
    "                image = image.resize((224, 224))\n",
    "                image = image.convert('RGB')\n",
    "                display(image)\n",
    "            # Use this to display the RET image/s\n",
    "            else:\n",
    "                fig, ax = plt.subplots(1, len(output), figsize=(3 * len(output), 3))\n",
    "                for i, (img, k) in enumerate(output):\n",
    "                    image = np.array(img)\n",
    "                    ax[i].imshow(img)\n",
    "                    ax[i].set_title(f'Retrieval #{i+1} - K #{k+1}')\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "# Load model used in the paper.\n",
    "model_dir = '../src/fromage_inf/fromage_model/'\n",
    "model = models.load_fromage(model_dir)\n",
    "\n",
    "# Load the relations dictionary to make the relations.\n",
    "relations = pickle.load(open(\"../src/code/relations_dict.pkl\", \"rb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve all dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
